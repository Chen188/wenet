{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1659d00a",
   "metadata": {},
   "source": [
    "## Notebook环境\n",
    "Notebook的运行环境可以选择conda_tensorflow_p36，这里所用的sagemaker版本为2.42.0，接下来我们会安装对应的版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install sagemaker==2.42.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14472ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "role   = get_execution_role()\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eac752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-022346938362'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896270d0",
   "metadata": {},
   "source": [
    "## 准备Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6d0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.Session().region_name\n",
    "ecr_repository = 'sagemaker-wenet'\n",
    "\n",
    "# 登录ECR服务\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbbab2",
   "metadata": {},
   "source": [
    "### 创建注册表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ed83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sagemaker-wenet' already exists in the registry with id '022346938362'\n"
     ]
    }
   ],
   "source": [
    "!aws ecr create-repository --repository-name $ecr_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51226762",
   "metadata": {},
   "source": [
    "### 构建训练镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e6995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8.1-gpu-py36-cu111-ubuntu18.04\n",
      "\n",
      "RUN cd / && \\\n",
      "    pip install ninja && \\\n",
      "    apt update && \\\n",
      "    apt-get install sox libsox-dev libsox-fmt-all pkg-config -y && \\\n",
      "    CUDNN_VERSION=8.0.5.39 && \\\n",
      "apt-get install cuda-nvrtc-11-1 cuda-nvrtc-dev-11-1 libcudnn8-dev=$CUDNN_VERSION-1+cuda11.1 -y && \\\n",
      "    TORCHAUDIO_VERSION=v0.8.1 && \\\n",
      "    git clone -b ${TORCHAUDIO_VERSION} https://github.com/pytorch/audio torchaudio && \\\n",
      "    cd torchaudio && \\\n",
      "    git submodule update --init --recursive && \\\n",
      "    pip install .\n",
      "\n",
      "COPY ./requirements.txt /tmp/\n",
      "\n",
      "RUN pip install -r /tmp/requirements.txt && \\\n",
      "    pip install sagemaker-training && \\\n",
      "    apt-get clean\n",
      "    "
     ]
    }
   ],
   "source": [
    "training_docker_file_path = '/fsx/wenet_smddp'\n",
    "\n",
    "!cat $training_docker_file_path/Dockerfile-py36-pt1.8.1-cu111-sox-ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751822b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 构建训练镜像并推送到ECR\n",
    "tag = ':training-pt181'\n",
    "training_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "print('training_repository_uri: ', training_repository_uri)\n",
    "\n",
    "!cd $training_docker_file_path && docker build -t \"$ecr_repository$tag\" . -f Dockerfile-py36-pt1.8.1-cu111-sox-ready\n",
    "!docker tag {ecr_repository + tag} $training_repository_uri\n",
    "!docker push $training_repository_uri\n",
    "\n",
    "\n",
    "# !docker pull $training_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6286eb",
   "metadata": {},
   "source": [
    "### 构建推理镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9977a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM ubuntu:latest\n",
      "MAINTAINER <zhendong.peng@mobvoi.com>\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list\n",
      "RUN apt-get update && apt-get install -y git cmake wget build-essential\n",
      "RUN git clone https://github.com/mobvoi/wenet.git /home/wenet\n",
      "ARG model=20210327_unified_transformer_exp_server.tar.gz\n",
      "RUN wget -P /home http://mobvoi-speech-public.ufile.ucloud.cn/public/wenet/aishell2/$model\n",
      "RUN tar -xzf /home/$model -C /home\n",
      "ARG build=/home/wenet/runtime/server/x86/build\n",
      "RUN mkdir $build && cmake -S $build/.. -B $build\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoding_docker_file_path='/fsx/wenet_smddp/runtime/server/x86'\n",
    "\n",
    "!cat $decoding_docker_file_path/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db053cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建推理容器并推送到ECR\n",
    "tag = ':decoding'\n",
    "decoding_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "print('decoding_repository_uri: ', decoding_repository_uri)\n",
    "\n",
    "\n",
    "!cd $decoding_docker_file_path && docker build -t \"$ecr_repository$tag\" .\n",
    "!docker tag {ecr_repository + tag} $decoding_repository_uri\n",
    "!docker push $decoding_repository_uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf35d2",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d65ef",
   "metadata": {},
   "source": [
    "### 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c48b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /fsx/wenet_smddp/examples/aishell/s0 && \\\n",
    "bash run.sh --stage -1 --stop_stage -1 --data /fsx/asr-data/OpenSLR/33\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd54f1e",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a270cb19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "# bash run.sh --stage 4 --stop_stage 4 --trail_dir /opt/ml/input/data/train --train_set train --data /opt/ml/input/data/33\n",
    "\n",
    "# 指定文件系统的id.\n",
    "file_system_id = 'fs-0f8a3b8eef47b6ff8'\n",
    "# 提供数据集所在的路径，注意格式\n",
    "file_system_path = '/yobzhbmv'\n",
    "# 指定挂载文件系统的访问模式，支持\"ro\"（只读）或\"rw\"（读写）两种，注意内置算法只支持 以 ro 的方式挂载\n",
    "file_system_access_mode = 'rw'\n",
    "# 指定文件系统的类型, 支持\"EFS\" 或 \"FSxLustre\"两种.\n",
    "file_system_type = 'FSxLustre'\n",
    "# 以VPC内的方式启动 Amazon SageMaker 训练任务,指定所在子网和安全组，subnet需要为list或者tuple格式\n",
    "security_group_ids = ['sg-04acfc98f6929ee4e']\n",
    "# subnets= ['vpc-3c49de46']\n",
    "subnets= ['subnet-07ce0ab63b4cfeb25']\n",
    "\n",
    "# 定义数据输入\n",
    "file_system_input_train = FileSystemInput(file_system_id=file_system_id,\n",
    "                                  file_system_type=file_system_type,\n",
    "                                  directory_path=file_system_path,\n",
    "                                  file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "data_dir   = '/opt/ml/input/data/train/asr-data/OpenSLR/33'\n",
    "trail_dir  = '/opt/ml/input/data/train/sm-train/trail0'\n",
    "shared_dir = '/opt/ml/input/data/train/sm-train/shared'\n",
    "# shared_dir = '/opt/ml/input/data/train/shared'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca7df6",
   "metadata": {},
   "source": [
    "## 数据预处理 - SageMaker托管实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66cd5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 09:49:56 Starting - Starting the training job...\n",
      "2021-06-08 09:49:58 Starting - Launching requested ML instances......\n",
      "2021-06-08 09:51:11 Starting - Preparing the instances for training......\n",
      "2021-06-08 09:52:06 Downloading - Downloading input data\n",
      "2021-06-08 09:52:06 Training - Downloading the training image...........\u001b[34m2021-06-08 09:54:06,765 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-08 09:54:08,241 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-08 09:54:08,251 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-08 09:54:08,258 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"stop_stage\": 3,\n",
      "        \"data\": \"/opt/ml/input/data/train/asr-data/OpenSLR/33\",\n",
      "        \"stage\": 0,\n",
      "        \"trail_dir\": \"/opt/ml/input/data/train/sm-train/trail0\",\n",
      "        \"train_set\": \"train\",\n",
      "        \"shared_dir\": \"/opt/ml/input/data/train/sm-train/shared\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-wenet-2021-06-08-09-49-53-057\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-022346938362/sagemaker-wenet-2021-06-08-09-49-53-057/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"examples/aishell/s0/sm-run.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"examples/aishell/s0/sm-run.sh\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"data\":\"/opt/ml/input/data/train/asr-data/OpenSLR/33\",\"shared_dir\":\"/opt/ml/input/data/train/sm-train/shared\",\"stage\":0,\"stop_stage\":3,\"trail_dir\":\"/opt/ml/input/data/train/sm-train/trail0\",\"train_set\":\"train\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=examples/aishell/s0/sm-run.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=examples/aishell/s0/sm-run.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-022346938362/sagemaker-wenet-2021-06-08-09-49-53-057/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"data\":\"/opt/ml/input/data/train/asr-data/OpenSLR/33\",\"shared_dir\":\"/opt/ml/input/data/train/sm-train/shared\",\"stage\":0,\"stop_stage\":3,\"trail_dir\":\"/opt/ml/input/data/train/sm-train/trail0\",\"train_set\":\"train\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-wenet-2021-06-08-09-49-53-057\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-022346938362/sagemaker-wenet-2021-06-08-09-49-53-057/source/sourcedir.tar.gz\",\"module_name\":\"examples/aishell/s0/sm-run.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"examples/aishell/s0/sm-run.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--data\",\"/opt/ml/input/data/train/asr-data/OpenSLR/33\",\"--shared_dir\",\"/opt/ml/input/data/train/sm-train/shared\",\"--stage\",\"0\",\"--stop_stage\",\"3\",\"--trail_dir\",\"/opt/ml/input/data/train/sm-train/trail0\",\"--train_set\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_STOP_STAGE=3\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=/opt/ml/input/data/train/asr-data/OpenSLR/33\u001b[0m\n",
      "\u001b[34mSM_HP_STAGE=0\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIL_DIR=/opt/ml/input/data/train/sm-train/trail0\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_SET=train\u001b[0m\n",
      "\u001b[34mSM_HP_SHARED_DIR=/opt/ml/input/data/train/sm-train/shared\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/bin/sh -c ./examples/aishell/s0/sm-run.sh --data /opt/ml/input/data/train/asr-data/OpenSLR/33 --shared_dir /opt/ml/input/data/train/sm-train/shared --stage 0 --stop_stage 3 --trail_dir /opt/ml/input/data/train/sm-train/trail0 --train_set train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mexpr: syntax error: unexpected argument ‘1’\u001b[0m\n",
      "\n",
      "2021-06-08 09:54:05 Training - Training image download completed. Training in progress.\u001b[34mPreparing /opt/ml/input/data/train/sm-train/shared/data/train transcriptions\u001b[0m\n",
      "\u001b[34mPreparing /opt/ml/input/data/train/sm-train/shared/data/dev transcriptions\u001b[0m\n",
      "\u001b[34mPreparing /opt/ml/input/data/train/sm-train/shared/data/test transcriptions\u001b[0m\n",
      "\u001b[34mlocal/aishell_data_prep.sh: AISHELL data preparation succeeded\u001b[0m\n",
      "\u001b[34mprocessed 1000 wavs, 452485 frames\u001b[0m\n",
      "\u001b[34mprocessed 2000 wavs, 906068 frames\u001b[0m\n",
      "\u001b[34mprocessed 3000 wavs, 1353788 frames\u001b[0m\n",
      "\u001b[34mprocessed 4000 wavs, 1795139 frames\u001b[0m\n",
      "\u001b[34mprocessed 5000 wavs, 2244717 frames\u001b[0m\n",
      "\u001b[34mprocessed 6000 wavs, 2694492 frames\u001b[0m\n",
      "\u001b[34mprocessed 7000 wavs, 3144493 frames\u001b[0m\n",
      "\u001b[34mprocessed 8000 wavs, 3592239 frames\u001b[0m\n",
      "\u001b[34mprocessed 9000 wavs, 4045299 frames\u001b[0m\n",
      "\u001b[34mprocessed 10000 wavs, 4491791 frames\u001b[0m\n",
      "\u001b[34mprocessed 11000 wavs, 4938581 frames\u001b[0m\n",
      "\u001b[34mprocessed 12000 wavs, 5391063 frames\u001b[0m\n",
      "\u001b[34mprocessed 13000 wavs, 5840177 frames\u001b[0m\n",
      "\u001b[34mprocessed 14000 wavs, 6291375 frames\u001b[0m\n",
      "\u001b[34mprocessed 15000 wavs, 6733667 frames\u001b[0m\n",
      "\u001b[34mprocessed 16000 wavs, 7188528 frames\u001b[0m\n",
      "\u001b[34mprocessed 17000 wavs, 7644227 frames\u001b[0m\n",
      "\u001b[34mprocessed 18000 wavs, 8091894 frames\u001b[0m\n",
      "\u001b[34mprocessed 19000 wavs, 8539084 frames\u001b[0m\n",
      "\u001b[34mprocessed 20000 wavs, 8993204 frames\u001b[0m\n",
      "\u001b[34mprocessed 21000 wavs, 9438993 frames\u001b[0m\n",
      "\u001b[34mprocessed 22000 wavs, 9888653 frames\u001b[0m\n",
      "\u001b[34mprocessed 23000 wavs, 10335890 frames\u001b[0m\n",
      "\u001b[34mprocessed 24000 wavs, 10789490 frames\u001b[0m\n",
      "\u001b[34mprocessed 25000 wavs, 11237997 frames\u001b[0m\n",
      "\u001b[34mprocessed 26000 wavs, 11680181 frames\u001b[0m\n",
      "\u001b[34mprocessed 27000 wavs, 12126205 frames\u001b[0m\n",
      "\u001b[34mprocessed 28000 wavs, 12574066 frames\u001b[0m\n",
      "\u001b[34mprocessed 29000 wavs, 13028190 frames\u001b[0m\n",
      "\u001b[34mprocessed 30000 wavs, 13480419 frames\u001b[0m\n",
      "\u001b[34mprocessed 31000 wavs, 13941705 frames\u001b[0m\n",
      "\u001b[34mprocessed 32000 wavs, 14389739 frames\u001b[0m\n",
      "\u001b[34mprocessed 33000 wavs, 14845074 frames\u001b[0m\n",
      "\u001b[34mprocessed 34000 wavs, 15296581 frames\u001b[0m\n",
      "\u001b[34mprocessed 35000 wavs, 15744470 frames\u001b[0m\n",
      "\u001b[34mprocessed 36000 wavs, 16188363 frames\u001b[0m\n",
      "\u001b[34mprocessed 37000 wavs, 16644571 frames\u001b[0m\n",
      "\u001b[34mprocessed 38000 wavs, 17092674 frames\u001b[0m\n",
      "\u001b[34mprocessed 39000 wavs, 17546945 frames\u001b[0m\n",
      "\u001b[34mprocessed 40000 wavs, 17996620 frames\u001b[0m\n",
      "\u001b[34mprocessed 41000 wavs, 18440399 frames\u001b[0m\n",
      "\u001b[34mprocessed 42000 wavs, 18884752 frames\u001b[0m\n",
      "\u001b[34mprocessed 43000 wavs, 19334927 frames\u001b[0m\n",
      "\u001b[34mprocessed 44000 wavs, 19786897 frames\u001b[0m\n",
      "\u001b[34mprocessed 45000 wavs, 20238857 frames\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bash run.sh --stage 4 --stop_stage 4 --train_set train  \\\n",
    "    --data /opt/ml/input/data/train/asr-data/OpenSLR/33 \\\n",
    "    --trail_dir /opt/ml/input/data/train/sm-train/trail0 \\\n",
    "    --shared_dir /opt/ml/input/data/train/sm-train/shared \n",
    "\n",
    "# /opt/ml/input/data/train  <==> /fsx\n",
    "# /opt/ml/input/data/train/asr-data/OpenSLR/33  <==> /fsx/asr-data/OpenSLR/33\n",
    "# /opt/ml/input/data/train/sm-train ==> /fsx/sm-train\n",
    "\n",
    "hp= {\n",
    "    'stage': 0, 'stop_stage': 3, 'train_set':'train', \n",
    "    'data': data_dir, 'trail_dir': trail_dir, 'shared_dir': shared_dir\n",
    "}\n",
    "\n",
    "estimator=PyTorch(\n",
    "    entry_point='examples/aishell/s0/sm-run.sh',\n",
    "    image_uri=training_repository_uri,\n",
    "    instance_type='ml.c5.4xlarge',\n",
    "    instance_count=1,\n",
    "    source_dir='.',\n",
    "    role=role,\n",
    "    hyperparameters=hp,\n",
    "    \n",
    "    subnets=subnets,\n",
    "    security_group_ids=security_group_ids,\n",
    "    \n",
    "    debugger_hook_config=False,\n",
    "    disable_profiler=True\n",
    ")\n",
    "\n",
    "# estimator.fit({'train':'file:///fsx/trail_local_0/', 'wav':'file:///fsx/asr-data/OpenSLR/33/data_aishell/wav/'})\n",
    "\n",
    "estimator.fit(inputs={'train': file_system_input_train})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996472fe",
   "metadata": {},
   "source": [
    "## 模型训练 - SageMaker托管实例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c3c9dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fsx/wenet_smddp/examples/aishell/s0\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f797803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /fsx/wenet_smddp\n",
    "\n",
    "# bash run.sh --stage 4 --stop_stage 4 --train_set train  \\\n",
    "#     --data /opt/ml/input/data/train/asr-data/OpenSLR/33 \\\n",
    "#     --trail_dir /opt/ml/input/data/train/sm-train/trail0 \\\n",
    "#     --shared_dir /opt/ml/input/data/train/sm-train/shared \n",
    "\n",
    "\n",
    "data_dir   = '/opt/ml/input/data/train/asr-data/OpenSLR/33'\n",
    "trail_dir  = '/opt/ml/input/data/train/sm-train/trail0'\n",
    "shared_dir = '/opt/ml/input/data/train/sm-train/shared'\n",
    "\n",
    "# instance_type='ml.g4dn.4xlarge'\n",
    "instance_type='ml.p4d.24xlarge'\n",
    "instance_count = 2\n",
    "# CUDA_VISIBLE_DEVICES='0,1,2,3'\n",
    "CUDA_VISIBLE_DEVICES='0,1,2,3,4,5,6,7'\n",
    "\n",
    "hp= {\n",
    "    'stage': 4, 'stop_stage': 4, 'train_set':'train', \n",
    "    'data': data_dir, 'trail_dir': trail_dir, 'shared_dir': shared_dir,\n",
    "    'CUDA_VISIBLE_DEVICES': CUDA_VISIBLE_DEVICES, \n",
    "    'ddp_init_path': '/opt/ml',\n",
    "    'num_nodes': instance_count\n",
    "}\n",
    "\n",
    "estimator=PyTorch( \n",
    "    entry_point='examples/aishell/s0/sm-run.sh',\n",
    "    image_uri=training_repository_uri,\n",
    "#     image_uri='022346938362.dkr.ecr.us-east-1.amazonaws.com/sagemaker-wenet:training-pt181',\n",
    "    instance_type =instance_type,\n",
    "    instance_count=instance_count,\n",
    "    source_dir='.',\n",
    "    role=role,\n",
    "    hyperparameters=hp,\n",
    "    \n",
    "    subnets=subnets,\n",
    "    security_group_ids=security_group_ids,\n",
    "    \n",
    "    debugger_hook_config=False,\n",
    "    disable_profiler=True,\n",
    "    distribution = {\n",
    "        'smdistributed':{\n",
    "            'dataparallel':{\n",
    "                'enabled': True, \n",
    "#                 \"custom_mpi_options\": \"-verbose -x NCCL_DEBUG=VERSION\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Parameters required to enable checkpointing\n",
    "#     checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "#     checkpoint_local_path=checkpoint_local_path\n",
    ")\n",
    "\n",
    "\n",
    "estimator.fit(inputs={'train': file_system_input_train})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3ce65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
